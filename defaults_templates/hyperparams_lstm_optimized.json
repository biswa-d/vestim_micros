{
    "_COMMENT": "Optimized hyperparameters for LSTM training - balances speed and memory efficiency",
    "FEATURE_COLUMNS": [
        "SOC",
        "Current",
        "Temp"
    ],
    "TARGET_COLUMN": "Voltage",
    "MODEL_TYPE": "LSTM",
    "LAYERS": "2",
    "HIDDEN_UNITS": "32",
    "DROPOUT_PROB": "0.2",
    "LSTM_USE_LAYERNORM": false,
    "TRAINING_METHOD": "Sequence-to-Sequence",
    "LOOKBACK": "150",
    "_COMMENT_LOOKBACK": "Reduced from 400 to 150 for faster training while maintaining context",
    "BATCH_SIZE": "256",
    "_COMMENT_BATCH_SIZE": "Increased from 200 to 256 for better GPU utilization",
    "BATCH_TRAINING": true,
    "SCHEDULER_TYPE": "StepLR",
    "INITIAL_LR": "0.001",
    "LR_PARAM": "0.5",
    "LR_PERIOD": "5",
    "PLATEAU_PATIENCE": "10",
    "PLATEAU_FACTOR": "0.1",
    "VALID_PATIENCE": "15",
    "VALID_FREQUENCY": "1",
    "MAX_EPOCHS": "100",
    "REPETITIONS": 1,
    "DEVICE_SELECTION": "cuda:0",
    "USE_MIXED_PRECISION": true,
    "_COMMENT_MIXED_PRECISION": "Enable for NVIDIA GPUs with Tensor Cores (RTX series, A100, etc.)",
    "OPTIMIZER_TYPE": "Adam",
    "WEIGHT_DECAY": "0.0001",
    "NUM_WORKERS": "2",
    "_COMMENT_NUM_WORKERS": "Conservative for LSTM - auto-adjusted based on available RAM",
    "PIN_MEMORY": true,
    "PREFETCH_FACTOR": "2",
    "_COMMENT_PREFETCH": "Lower prefetch for LSTM due to larger sequence data",
    "PERSISTENT_WORKERS": true,
    "MAX_TRAINING_TIME_SECONDS": 0,
    "TRAIN_VAL_SPLIT": "0.8",
    "LR_DROP_FACTOR": "0.5",
    "LR_DROP_PERIOD": "1",
    "ValidFrequency": "1",
    "SEQUENCE_SPLIT_METHOD": "temporal",
    "MAX_TRAIN_HOURS": "0",
    "MAX_TRAIN_MINUTES": "0",
    "MAX_TRAIN_SECONDS": "0",
    "_PERFORMANCE_NOTES": [
        "This configuration is optimized for LSTM training speed and memory efficiency",
        "Key optimizations:",
        "1. LOOKBACK reduced to 150 (from typical 400) for faster computation",
        "2. BATCH_SIZE increased to 256 for better GPU utilization",
        "3. NUM_WORKERS set conservatively to 2 for LSTM sequence processing",
        "4. Mixed precision training enabled for compatible GPUs",
        "5. cuDNN benchmark and CPU threading optimizations applied automatically",
        "Adjust LOOKBACK and BATCH_SIZE based on:",
        "- Your sequence length requirements",
        "- Available GPU memory (reduce BATCH_SIZE if OOM)",
        "- Available system RAM (reduce NUM_WORKERS if OOM)",
        "For low memory systems (<8GB RAM): Set NUM_WORKERS to 0, BATCH_SIZE to 128"
    ]
}
