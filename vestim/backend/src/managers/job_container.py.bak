import os
import time
import logging
import threading
from datetime import datetime
from multiprocessing import Event
from typing import Dict, Any, Optional
import asyncio
from concurrent.futures import ThreadPoolExecutor
from vestim.backend.src.models.phase_templates import get_phase_template, initialize_phase_data

class JobContainer:
    """
    Container that manages all aspects of a single job.
    Acts as a coordinator for job-specific managers and shared services.
    Provides clean isolation between jobs and handles asynchronous task execution.
    """
    def __init__(self, job_id: str, job_folder: str, selections: dict):
        self.job_id = job_id
        self.job_folder = job_folder
        self.selections = selections
        self.logger = logging.getLogger(f"{__name__}.{job_id}")
        
        # Job state and progress with detailed phase tracking
        self.status = "created"
        self.progress_message = "Job created"
        self.progress_percent = 0
        self.current_phase = "data_import"  # Start with data_import phase
        
        # Initialize current phase data using templates
        self.current_phase_data = initialize_phase_data(self.current_phase)
        
        # Phase progress tracking for overall job phases
        self.phase_progress = {
            "data_import": {"status": "pending", "progress": 0, "message": "Waiting to start"},
            "data_augmentation": {"status": "pending", "progress": 0, "message": "Waiting to start"},
            "hyperparameters": {"status": "pending", "progress": 0, "message": "Waiting to start"},
            "training_setup": {"status": "pending", "progress": 0, "message": "Waiting to start"},
            "training": {"status": "pending", "progress": 0, "message": "Waiting to start"},
            "testing": {"status": "pending", "progress": 0, "message": "Waiting to start"}
        }
        
        # Training history persistence (for GUI restoration)
        self.training_history = []  # Full training history
        self.training_logs = []     # Training logs
        self.stop_training_flag = False  # Flag for graceful training stop
        
        self.created_at = datetime.now().isoformat()
        self.updated_at = self.created_at
        
        # GUI state persistence - determines which GUI to show when reopening
        self.gui_ready_for_phase = "data_import"  # Which GUI should be shown
        self.requires_user_input = True  # Whether this job needs user interaction
        self.current_gui_type = None  # Track current GUI type
        
        # Managers registry - job-specific instances from common scripts
        self.managers = {}
        self.manager_lock = threading.Lock()
        
        # Process management
        self.process = None
        self.stop_flag = Event()
        
        # Job details and history
        self.details = {}
        self.task_progress = {}  # Task-specific progress tracking
        
        # Thread pool for asynchronous operations
        self.thread_pool = ThreadPoolExecutor(max_workers=4, thread_name_prefix=f"Job-{job_id}")
        
        # Services - shared instances (microservices pattern)
        self._data_processing_service = None
        self._data_augmentation_service = None
        self._model_training_service = None
        
        self.logger.info(f"JobContainer created for {job_id}")
    
    def update_status(self, status: str, message: str, progress_percent: float = None, **kwargs):
        """Update job status with thread safety"""
        with self.manager_lock:
            self.status = status
            self.progress_message = message
            if progress_percent is not None:
                self.progress_percent = progress_percent
            self.updated_at = datetime.now().isoformat()
            
            # Update details with any additional info
            if kwargs:
                self.details.update(kwargs)
            
            self.logger.info(f"Status updated: {status} - {message} ({progress_percent}%)")
    def update_task_progress(self, task_id: str, task_data: dict):
        """Update progress for a specific task"""
        with self.manager_lock:
            self.task_progress[task_id] = task_data
            self.updated_at = datetime.now().isoformat()
    
    # === SERVICE GETTERS (Shared Services - Microservices Pattern) ===
    
    def get_data_processing_service(self):
        """Get shared data processing service instance"""
        if self._data_processing_service is None:
            from vestim.backend.src.services.data_processing_service import DataProcessingService
            self._data_processing_service = DataProcessingService()
        return self._data_processing_service
    
    def get_data_augmentation_service(self):
        """Get shared data augmentation service instance"""
        if self._data_augmentation_service is None:
            from vestim.backend.src.services.data_processor.src.data_augment_service import DataAugmentService
            self._data_augmentation_service = DataAugmentService()
            self.logger.info("Created shared data augmentation service")
        return self._data_augmentation_service
    
    def get_model_training_service(self):
        """Get shared model training service instance"""
        if self._model_training_service is None:
            from vestim.backend.src.services.model_training.src.training_task_service import TrainingTaskService
            self._model_training_service = TrainingTaskService()
        return self._model_training_service
    
    # === MANAGER GETTERS (Job-Specific Instances from Common Scripts) ===
    
    def get_training_task_manager(self):
        """Get or create job-specific training task manager from common script"""
        with self.manager_lock:
            if 'training_task_manager' not in self.managers:
                from vestim.backend.src.managers.training_task_manager_qt import TrainingTaskManager
                self.managers['training_task_manager'] = TrainingTaskManager()
                self.logger.info("Created job-specific training task manager")
            return self.managers['training_task_manager']
    
    def get_data_processing_manager(self):
        """Get or create job-specific data processing manager"""
        with self.manager_lock:
            if 'data_processing_manager' not in self.managers:
                # Create job-specific manager instance (NOT the service)
                # This would be a manager that coordinates with the service
                self.logger.info("Data processing manager would be created here")
                # For now, we'll use the service directly
                return None
            return self.managers['data_processing_manager']
    
    def get_data_augmentation_manager(self):
        """Get or create job-specific data augmentation manager from common script"""
        with self.manager_lock:
            if 'data_augmentation_manager' not in self.managers:
                from vestim.backend.src.managers.data_augment_manager_qt import DataAugmentManager
                self.managers['data_augmentation_manager'] = DataAugmentManager(
                    self.job_id, self.job_folder
                )
                self.logger.info("Created job-specific data augmentation manager")
            return self.managers['data_augmentation_manager']
    
    
    def get_hyperparams_manager(self):
        """Get or create job-specific hyperparameters manager"""
        with self.manager_lock:
            if 'hyperparams_manager' not in self.managers:
                from vestim.backend.src.managers.hyper_param_manager_qt import VEstimHyperParamManager
                self.managers['hyperparams_manager'] = VEstimHyperParamManager()
                self.logger.info("Created job-specific hyperparams manager")
            return self.managers['hyperparams_manager']
    
    def get_training_setup_manager(self):
        """Get or create job-specific training setup manager"""
        with self.manager_lock:
            if 'training_setup_manager' not in self.managers:
                from vestim.backend.src.managers.training_setup_manager_qt import VEstimTrainingSetupManager
                self.managers['training_setup_manager'] = VEstimTrainingSetupManager(
                    self.job_id, self.job_folder, {}
                )
                self.logger.info("Created job-specific training setup manager")
            return self.managers['training_setup_manager']
    
    # === ASYNCHRONOUS TASK COORDINATION ===
    
    def run_data_processing_async(self, train_files: list, test_files: list, data_source: str, callback=None):
        """
        Coordinate data processing using shared DataProcessingService.
        Runs asynchronously and updates job status.
        """
        def process_data():
            try:
                self.update_status("processing_data", "Starting data processing", 10)
                
                # Use shared data processing service
                data_service = self.get_data_processing_service()
                success = data_service.process_data_files(
                    job_id=self.job_id,
                    job_folder=self.job_folder,
                    train_files=train_files,
                    test_files=test_files,
                    data_source=data_source
                )
                
                if success:
                    self.update_status("data_processed", "Data processing completed", 25)
                    self.details.update({
                        "data_processed": True,
                        "data_source": data_source,
                        "train_files": train_files,
                        "test_files": test_files
                    })
                else:
                    self.update_status("error", "Data processing failed", 0)                
                if callback:
                    callback(success)
                
                return success
            except Exception as e:
                self.logger.error(f"Error in async data processing: {e}", exc_info=True)
                self.update_status("error", f"Data processing failed: {str(e)}", 0)
                if callback:
                    callback(False)
                return False
        
        # Submit to thread pool for non-blocking execution
        future = self.thread_pool.submit(process_data)
        return future
    
    def run_data_augmentation_async(self, augmentation_params: dict, callback=None):
        """Run data augmentation asynchronously using shared service with job-specific manager"""
        def augment_data():
            try:
                self.update_status("augmenting_data", "Starting data augmentation", 30)
                
                # Get shared data augmentation service and job-specific manager
                augment_service = self.get_data_augmentation_service()
                augment_manager = self.get_data_augmentation_manager()
                
                if not augment_service:
                    self.logger.error("Data augmentation service not available")
                    self.update_status("error", "Data augmentation service not available", 0)
                    if callback:
                        callback(False)
                    return False
                
                # Use the service to perform data augmentation coordinated by the manager
                # The manager provides job-specific context, service does the work
                success = augment_service.process_job_data(
                    job_folder=self.job_folder,
                    **augmentation_params
                )
                
                if success:
                    self.update_status("data_augmented", "Data augmentation completed", 50)
                    self.details.update({
                        "data_augmented": True,
                        "augmentation_params": augmentation_params
                    })
                else:
                    self.update_status("error", "Data augmentation failed", 0)
                
                if callback:
                    callback(success)
                return success
                
            except Exception as e:
                self.logger.error(f"Error in async data augmentation: {e}", exc_info=True)
                self.update_status("error", f"Data augmentation failed: {str(e)}", 0)
                if callback:
                    callback(False)
                return False
        
        future = self.thread_pool.submit(augment_data)
        return future
    
    def run_training_async(self, training_params: dict, callback=None):
        """Run model training asynchronously using shared service"""
        def train_model():
            try:
                self.update_status("training", "Starting model training", 60)
                
                # Use shared model training service with job-specific manager
                training_service = self.get_model_training_service()
                training_manager = self.get_training_task_manager()
                  # TODO: Implement training coordination
                # success = training_service.train_model(training_manager, training_params)
                
                self.update_status("training_completed", "Model training completed", 100)
                
                if callback:
                    callback(True)
                return True
            except Exception as e:
                self.logger.error(f"Error in async training: {e}", exc_info=True)
                self.update_status("error", f"Training failed: {str(e)}", 0)
                if callback:
                    callback(False)
                return False
        
        future = self.thread_pool.submit(train_model)
        return future
    
    # === PHASE MANAGEMENT METHODS ===
    
    def update_phase_progress(self, phase: str, progress: float, message: str, **kwargs):
        """Update progress for a specific phase"""
        with self.manager_lock:
            if phase in self.phase_progress:
                self.phase_progress[phase].update({
                    "progress": progress,
                    "message": message,
                    "status": kwargs.get("status", self.phase_progress[phase]["status"])
                })
                
                # Update current phase data if this is the current phase
                if phase == self.current_phase:
                    self.current_phase_data.update(kwargs)
                    self.current_phase_data["_last_updated"] = datetime.now().isoformat()
                
                self.updated_at = datetime.now().isoformat()
                self.logger.info(f"Phase {phase} progress: {progress}% - {message}")
    
    def get_current_phase_data(self) -> Dict[str, Any]:
        """Get current phase data"""
        with self.manager_lock:
            return self.current_phase_data.copy()
    
    def update_current_phase_data(self, **updates):
        """Update current phase data"""
        with self.manager_lock:
            self.current_phase_data.update(updates)
            self.current_phase_data["_last_updated"] = datetime.now().isoformat()
            self.updated_at = datetime.now().isoformat()
    
    def transition_to_phase(self, new_phase: str, **initial_data):
        """Transition to a new phase"""
        with self.manager_lock:
            old_phase = self.current_phase
            self.current_phase = new_phase
            
            # Initialize new phase data
            self.current_phase_data = initialize_phase_data(new_phase, **initial_data)
            
            # Update GUI ready state
            self.gui_ready_for_phase = new_phase
            
            # Update phase status
            if new_phase in self.phase_progress:
                self.phase_progress[new_phase]["status"] = "active"
            
            # Mark old phase as completed if it exists
            if old_phase in self.phase_progress:
                self.phase_progress[old_phase]["status"] = "completed"
                self.phase_progress[old_phase]["progress"] = 100
            
            self.updated_at = datetime.now().isoformat()
            self.logger.info(f"Transitioned from {old_phase} to {new_phase}")
    
    def update_training_progress(self, epoch: int, train_loss: float, val_loss: float = None, 
                                patience: int = 0, **metrics):
        """Update training progress with detailed metrics"""
        with self.manager_lock:
            # Update current phase data if we're in training
            if self.current_phase == "training":
                self.current_phase_data.update({
                    "current_epoch": epoch,
                    "current_metrics": {
                        "train_loss": train_loss,
                        "val_loss": val_loss or 0.0,
                        **metrics
                    },
                    "patience_counter": patience,
                    "_last_updated": datetime.now().isoformat()
                })
            
            # Store in persistent training history
            history_entry = {
                "epoch": epoch,
                "train_loss": train_loss,
                "val_loss": val_loss,
                "timestamp": datetime.now().isoformat(),
                **metrics
            }
            self.training_history.append(history_entry)
            
            # Update phase progress
            if self.current_phase == "training" and "total_epochs" in self.current_phase_data:
                progress = (epoch / self.current_phase_data["total_epochs"]) * 100
                self.update_phase_progress("training", progress, 
                                         f"Epoch {epoch} - Loss: {train_loss:.4f}")
    
    def add_training_log(self, message: str, level: str = "info"):
        """Add a training log entry"""
        with self.manager_lock:
            log_entry = {
                "timestamp": datetime.now().isoformat(),
                "level": level,
                "message": message
            }
            self.training_logs.append(log_entry)
            
            # Limit log size
            if len(self.training_logs) > 1000:  # Keep last 1000 entries
                self.training_logs = self.training_logs[-1000:]
    
    def stop_training(self):
        """Set flag to stop training gracefully"""
        with self.manager_lock:
            self.stop_training_flag = True
            self.update_current_phase_data(training_status="stopping")
            self.update_phase_progress("training", self.phase_progress["training"]["progress"],
                                     "Stopping training after current epoch...")
            self.logger.info("Training stop requested - will stop after current epoch")
    
    def is_training_stopped(self) -> bool:
        """Check if training should be stopped"""
        return self.stop_training_flag
    
    def cleanup_managers(self):
        """Clean up all managers when job is done"""
        with self.manager_lock:
            for manager_name, manager in self.managers.items():
                try:
                    if hasattr(manager, 'cleanup'):
                        manager.cleanup()
                    self.logger.info(f"Cleaned up {manager_name}")
                except Exception as e:
                    self.logger.error(f"Error cleaning up {manager_name}: {e}")
            
            self.managers.clear()
            self.logger.info("All managers cleaned up")
    
    def set_process(self, process):
        """Set the process handle for this job"""
        self.process = process
    
    def is_running(self):
        """Check if the job process is running"""
        return self.process and self.process.is_alive()
    
    def stop(self):
        """Signal the job to stop gracefully"""
        self.stop_flag.set()
        self.update_status("stopping", "Job stop requested")
        
        if self.process and self.process.is_alive():
            # Give the process time to stop gracefully
            self.process.join(timeout=10)
            if self.process.is_alive():
                self.process.terminate()
                self.logger.warning(f"Had to forcefully terminate process for {self.job_id}")
    def get_summary(self):
        """Get a summary of the job container state"""
        with self.manager_lock:
            return {
                "job_id": self.job_id,
                "status": self.status,
                "progress_message": self.progress_message,
                "progress_percent": self.progress_percent,
                "current_phase": self.current_phase,
                "created_at": self.created_at,
                "updated_at": self.updated_at,
                "is_running": self.is_running(),
                "active_managers": list(self.managers.keys()),
                "task_progress": self.task_progress,
                "details": self.details
            }
    def get_detailed_state(self):
        """Get detailed state including all task progress"""
        summary = self.get_summary()
        summary.update({
            "job_folder": self.job_folder,
            "selections": self.selections,
            "phase_progress": self.phase_progress,
            "current_phase_data": self.current_phase_data,
            "gui_ready_for_phase": self.gui_ready_for_phase,
            "requires_user_input": self.requires_user_input,
            "training_history": self.training_history,
            "training_logs": self.training_logs,
            "stop_training_flag": self.stop_training_flag
        })
        return summary
    
    def get_status_summary(self):
        """Get a comprehensive status summary for dashboard display"""
        with self.manager_lock:
            return {
                "job_id": self.job_id,
                "status": self.status,
                "progress_message": self.progress_message,
                "progress_percent": self.progress_percent,
                "current_phase": self.current_phase,
                "phase_progress": self.phase_progress,
                "current_phase_data": self.current_phase_data,
                "gui_ready_for_phase": self.gui_ready_for_phase,
                "requires_user_input": self.requires_user_input,
                "created_at": self.created_at,
                "updated_at": self.updated_at,
                "is_running": self.is_running(),
                "active_managers": list(self.managers.keys()),
                "task_progress": self.task_progress,
                "details": self.details,
                "job_folder": self.job_folder,
                "selections": self.selections,
                "training_history": self.training_history[-100:],  # Last 100 entries for GUI
                "training_logs": self.training_logs[-50:],  # Last 50 log entries
                "stop_training_flag": self.stop_training_flag
            }
