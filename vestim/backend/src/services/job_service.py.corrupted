import os
import json
import itertools
from datetime import datetime
from vestim.config import OUTPUT_DIR
from vestim.logger_config import configure_job_specific_logging
import logging
import globil
import shutil
class JobService:
class JobService:
    _instance = None

    def __new__(cls):
        if not cls._instance:
            cls._instance = super(JobService, cls).__new__(cls)
        return cls._instance 'initialized'):
            self.initialized = True
    def __init__(self): = None
        if not hasattr(self, 'initialized'):__name__)
            self.initialized = True
            self.job_id = Nonerectory exists
            self.logger = logging.getLogger(__name__)
            
            # Ensure output directory existsle if it doesn't exist
            os.makedirs(OUTPUT_DIR, exist_ok=True)OUTPUT_DIR, 'job_registry.json')
            if not os.path.exists(self.job_registry_file):
            # Initialize the job registry file if it doesn't exist
            self.job_registry_file = os.path.join(OUTPUT_DIR, 'job_registry.json')
            if not os.path.exists(self.job_registry_file):
                with open(self.job_registry_file, 'w') as f:
                    json.dump({"jobs": []}, f, indent=4)ob directory."""
        self.job_id = f"job_{datetime.now().strftime('%Y%m%d-%H%M%S')}"
    def create_new_job(self, selections: dict):elf.job_id)
        """Generates a new job ID and creates the main job directory."""
        self.job_id = f"job_{datetime.now().strftime('%Y%m%d-%H%M%S')}"
        job_folder = os.path.join(OUTPUT_DIR, self.job_id)tus.json file
        os.makedirs(job_folder, exist_ok=True) 'status.json')
        job_info = {
        try:"job_id": self.job_id,
            configure_job_specific_logging(job_folder)
            self.logger.info(f"Job-specific logging configured for job: {self.job_id}")
        except Exception as e:time.now().isoformat(),
            self.logger.error(f"Failed to configure job-specific logging for {self.job_id}: {e}", exc_info=True)
            
        # Store the selections and initial status in a status.json file
        status_file = os.path.join(job_folder, 'status.json')
        job_info = {p(job_info, f, indent=4)
            "job_id": self.job_id,
            "status": "created",  global registry
            "selections": selections,
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()_id} with selections: {selections}")
        }
        return self.job_id, job_folder
        with open(status_file, 'w') as f:
            json.dump(job_info, f, indent=4)
            dd a job to the registry file."""
        # Register the job in the global registry
        self._register_job(job_info)try_file, 'r') as f:
                registry = json.load(f)
        self.logger.info(f"Created new job {self.job_id} with selections: {selections}")
            # Add the new job
        return self.job_id, job_folderb_info)
            
    def _register_job(self, job_info):ry file
        """Add a job to the registry file.""" 'w') as f:
        try:    json.dump(registry, f, indent=4)
            with open(self.job_registry_file, 'r') as f:
                registry = json.load(f)_info['job_id']} registered in the registry")
            pt Exception as e:
            # Add the new job(f"Failed to register job in registry: {e}", exc_info=True)
            registry["jobs"].append(job_info)
            te_job_status(self, job_id, status, message=None):
            # Write back to the registry file
            with open(self.job_registry_file, 'w') as f:
                json.dump(registry, f, indent=4)status.json')
                
            self.logger.info(f"Job {job_info['job_id']} registered in the registry")
        except Exception as e:f"Status file for job {job_id} not found")
            self.logger.error(f"Failed to register job in registry: {e}", exc_info=True)
        
    def update_job_status(self, job_id, status, message=None):
        """Update the status of a job."""
        job_folder = os.path.join(OUTPUT_DIR, job_id)
        status_file = os.path.join(job_folder, 'status.json')
            
        if not os.path.exists(status_file):
            self.logger.error(f"Status file for job {job_id} not found")
            return False["message"] = message
            job_info["updated_at"] = datetime.now().isoformat()
        try:
            # Update the job status fileas f:
            with open(status_file, 'r') as f:=4)
                job_info = json.load(f)
            # Update the job in the registry
            job_info["status"] = statusy(job_info)
            if message:
                job_info["message"] = messagetatus updated to: {status}")
            job_info["updated_at"] = datetime.now().isoformat()
            pt Exception as e:
            with open(status_file, 'w') as f:ate job status: {e}", exc_info=True)
                json.dump(job_info, f, indent=4)
            
            # Update the job in the registryfo):
            self._update_job_in_registry(job_info)
            
            self.logger.info(f"Job {job_id} status updated to: {status}")
            return Truey = json.load(f)
        except Exception as e:
            self.logger.error(f"Failed to update job status: {e}", exc_info=True)
            return Falsen enumerate(registry["jobs"]):
                if job["job_id"] == job_info["job_id"]:
    def _update_job_in_registry(self, job_info):fo
        """Update a job in the registry file."""
        try:
            with open(self.job_registry_file, 'r') as f:
                registry = json.load(f)_file, 'w') as f:
                json.dump(registry, f, indent=4)
            # Find and update the job
            for i, job in enumerate(registry["jobs"]):n registry: {e}", exc_info=True)
                if job["job_id"] == job_info["job_id"]:
                    registry["jobs"][i] = job_infoict):
                    break
            rates individual task configurations from a dictionary of hyperparameters,
            # Write back to the registry fileated values for tuning.
            with open(self.job_registry_file, 'w') as f:
                json.dump(registry, f, indent=4)urations from hyperparameters.")
        except Exception as e:
            self.logger.error(f"Failed to update job in registry: {e}", exc_info=True)
        fixed_params = {}
    def generate_task_configs(self, hyperparams: dict):
        """
        Generates individual task configurations from a dictionary of hyperparameters,
        some of which may contain comma-separated values for tuning.
        """     # Split string by comma, strip whitespace, and filter out empty strings
        self.logger.info("Generating task configurations from hyperparameters.")
                if options:
        # Separate fixed params from params that need to be iterated over
        fixed_params = {}
        tuning_params = {}le case where a key has a comma but no valid values (e.g., " , ")
                    self.logger.warning(f"Hyperparameter '{key}' contained commas but no valid values. Ignoring.")
        for key, value in hyperparams.items():
            if isinstance(value, str) and ',' in value:
                # Split string by comma, strip whitespace, and filter out empty strings
                options = [v.strip() for v in value.split(',') if v.strip()]
                if options:ers are being tuned, create a single task config
                    tuning_params[key] = optionstuning detected. Creating a single task.")
                else:yperparams]
                    # Handle case where a key has a comma but no valid values (e.g., " , ")
                    self.logger.warning(f"Hyperparameter '{key}' contained commas but no valid values. Ignoring.")
            else:ues = zip(*tuning_params.items())
                fixed_params[key] = valueys, v)) for v in itertools.product(*values)]
        
        if not tuning_params:nerated {len(param_combinations)} unique parameter combinations for tuning.")
            # If no parameters are being tuned, create a single task config
            self.logger.info("No hyperparameter tuning detected. Creating a single task.")
            return [hyperparams]
        for combo in param_combinations:
        # Generate the Cartesian product of all tuning parameter values
        keys, values = zip(*tuning_params.items())
        param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]
            
        self.logger.info(f"Generated {len(param_combinations)} unique parameter combinations for tuning.")

        # Create a full task configuration for each combination
        task_configs = []d
        for combo in param_combinations:
            config = fixed_params.copy()
            config.update(combo)D."""
            task_configs.append(config)
            
        return task_configs, job_id=None):
        """Get the folder path for a job, using current job ID if none provided."""
    def get_job_id(self):d if job_id else self.job_id
        return self.job_id
            return os.path.join(OUTPUT_DIR, id_to_use)
    def set_job_id(self, job_id):
        """Set the current job ID."""
        self.job_id = job_idf, job_id=None):
        id_to_use = job_id if job_id else self.job_id
    def get_job_folder(self, job_id=None):
        """Get the folder path for a job, using current job ID if none provided."""ocessed_data')
        id_to_use = job_id if job_id else self.job_id
        if id_to_use:lder
            return os.path.join(OUTPUT_DIR, id_to_use)
        return None
    def get_test_folder(self, job_id=None):
    def get_train_folder(self, job_id=None):lf.job_id
        id_to_use = job_id if job_id else self.job_id
        if id_to_use:os.path.join(self.get_job_folder(id_to_use), 'test_data', 'processed_data')
            folder = os.path.join(self.get_job_folder(id_to_use), 'train_data', 'processed_data')
            os.makedirs(folder, exist_ok=True)
            return folder
        return None
    def get_all_jobs(self):
    def get_test_folder(self, job_id=None):""
        id_to_use = job_id if job_id else self.job_id
        if id_to_use:h.exists(self.job_registry_file):
            folder = os.path.join(self.get_job_folder(id_to_use), 'test_data', 'processed_data')
            os.makedirs(folder, exist_ok=True)
            return foldergistry["jobs"]
        return None[]
        except Exception as e:
    def get_all_jobs(self):or(f"Failed to get all jobs: {e}", exc_info=True)
        """Get all jobs from the registry."""
        try:
            if os.path.exists(self.job_registry_file):
                with open(self.job_registry_file, 'r') as f:
                    registry = json.load(f)
                return registry["jobs"]
            return []n jobs:
        except Exception as e:"] == job_id:
            self.logger.error(f"Failed to get all jobs: {e}", exc_info=True)
            return []ne
        except Exception as e:
    def get_job_by_id(self, job_id):ed to get job by ID: {e}", exc_info=True)
        """Get a specific job by ID."""
        try:
            jobs = self.get_all_jobs()
            for job in jobs:nd their data."""
                if job["job_id"] == job_id:
                    return jobtories
            return None glob.glob(os.path.join(OUTPUT_DIR, "job_*"))
        except Exception as e:ths:
            self.logger.error(f"Failed to get job by ID: {e}", exc_info=True)
            return None
            # Reset the job registry
    def clear_all_jobs(self):b_registry_file, 'w') as f:
        """Delete all jobs and their data."""dent=4)
        try:    
            # Delete job directoriesbs have been cleared")
            job_paths = glob.glob(os.path.join(OUTPUT_DIR, "job_*"))
            for path in job_paths:
                shutil.rmtree(path, ignore_errors=True)s: {e}", exc_info=True)
            return False
            # Reset the job registry
            with open(self.job_registry_file, 'w') as f:
                json.dump({"jobs": []}, f, indent=4)
                lts_folder = os.path.join(self.get_job_folder(), 'test', 'results')
            self.logger.info("All jobs have been cleared")        self.logger.error(f"Failed to clear all jobs: {e}", exc_info=True)
            return Truelts_folder
        except Exception as e:            self.logger.error(f"Failed to clear all jobs: {e}", exc_info=True)            return False        def get_test_results_folder(self):        if self.job_id:            results_folder = os.path.join(self.get_job_folder(), 'test', 'results')            os.makedirs(results_folder, exist_ok=True)            return results_folder        return None            self.logger.error(f"Failed to clear all jobs: {e}", exc_info=True)            return False        def get_test_results_folder(self):        if self.job_id:            results_folder = os.path.join(self.get_job_folder(), 'test', 'results')            os.makedirs(results_folder, exist_ok=True)            return results_folder        return None